{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7827850",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. Introduction [purpose, agenda, alignment]\n",
    "    - What are GANs? \n",
    "    - the outline \n",
    "    - What do you know about GANs?\n",
    "2. Fundamental Concept [key definitions, concepts]\n",
    "    - GAN breakdown\n",
    "    - Components\n",
    "3. Deep Dive [architecture and workflow, step on how it works]\n",
    "    - whats the architecture\n",
    "    - How it works\n",
    "    - How to build one\n",
    "4. Real-world applications [use cases, how they impact your business/product]\n",
    "    - use cases\n",
    "    - impact on the business\n",
    "5. Interactions [Questions&Answers, polls, scenario discussion]\n",
    "    - QnA\n",
    "    - polls\n",
    "    - scenario discussion\n",
    "6. Hands-On [case study, practical implementation]\n",
    "    - case study\n",
    "    - implementation\n",
    "7. Conclusion [summary, resources, what to do next]\n",
    "    - summary pointers\n",
    "    - resources\n",
    "    - what next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690c359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf6b315e",
   "metadata": {},
   "source": [
    "# 1. Introduction [purpose, agenda, alignment]\n",
    "\n",
    "## What are GANs?\n",
    "\n",
    "<img src='g1.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce54dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you know about GANs?\n",
    "\n",
    "no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9602c55",
   "metadata": {},
   "source": [
    "simple example of GANs\n",
    "\n",
    "this person done not exists: https://thispersondoesnotexist.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62831e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a neural network architecture that will generate new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35778f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Coke ad generated by AI: https://www.facebook.com/watch/?v=1276572062941149"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57fda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inventor of GANs: Ian J. Goodfellow\n",
    "\n",
    "https://scholar.google.ca/citations?user=iYN86KEAAAAJ&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ffcaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "186076f2",
   "metadata": {},
   "source": [
    "# 2. Fundamental Concept [key definitions, concepts]\n",
    "\n",
    "### GAN breakdown and Components\n",
    "\n",
    "<img src='g2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41780c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 neural networks are in GANs\n",
    "\n",
    "1 - Generator: it will generate realistically fake values to fool the discriminator\n",
    "    - the network takes the random noise as input and produce data\n",
    "    - the goal is to generate data that is as close as possible to real data\n",
    "    \n",
    "2 - Discriminator: it will differentiate betweek fake and real values\n",
    "    - the network takes the real data and the data generated by Generator as input\n",
    "    - it differentiate between the two\n",
    "    - it outputs the probability that the given data is real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9806da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "465b3d85",
   "metadata": {},
   "source": [
    "# 3. Deep Dive [architecture and workflow, step on how it works]\n",
    "\n",
    "### whats the architecture\n",
    "\n",
    "<img src='g4.png' />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467c91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb5eab77",
   "metadata": {},
   "source": [
    "### How it works\n",
    "\n",
    "<img src='g11.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2025ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator\n",
    "\n",
    "input - random noise vector (sampled normal distribution) - starting point of data generation\n",
    "\n",
    "fully connected layers - used to transform the input noise vector into a suitable shape \n",
    "\n",
    "batch normalization - this technique is used between layers to stabilize learning \n",
    "                        by normalizing the ouput of previous layer\n",
    "\n",
    "activation function - ReLU activation\n",
    "\n",
    "transposed convolutional layer(deconvolutional layer) - \n",
    "            they upsample the input from the previous layer to a high dimension\n",
    "    the opposite of convolutional layer\n",
    "    \n",
    "reshaping layer - reshape it in desired output format\n",
    "\n",
    "output layer - having tanh activation function \n",
    "            - tanh is used to output pixel values in a normalized range [-1,1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba3e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Discriminator\n",
    "\n",
    "input - data samples which is either real or fake\n",
    "\n",
    "convolutional layer - helps in extracting features from the input image\n",
    "\n",
    "batch normalization - to stabilize learning\n",
    "\n",
    "activation function - Leaky ReLU activation\n",
    "                - it allows a small gradient when the unit is not active\n",
    "                - to maintain the gradient flow during training\n",
    "    \n",
    "pooling layer - reduce the dimensions of the input data\n",
    "\n",
    "fully connected layer - used to process the features extracted by convolutional layer\n",
    "\n",
    "output - scalar value between 0 and 1 (probability of the input sample as real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c56cda",
   "metadata": {},
   "source": [
    "### How to build one\n",
    "\n",
    "Basic implementation in pytorch on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e0845b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:03<00:00, 2881119.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 134687.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1281109.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4344476.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Epoch [0/20] Batch 0/938                   Loss D: 1.3752137422561646, Loss G: 0.7055636644363403\n",
      "Epoch [0/20] Batch 100/938                   Loss D: 0.31725192070007324, Loss G: 1.967050552368164\n",
      "Epoch [0/20] Batch 200/938                   Loss D: 0.1537465751171112, Loss G: 3.3735804557800293\n",
      "Epoch [0/20] Batch 300/938                   Loss D: 0.6559709310531616, Loss G: 10.448826789855957\n",
      "Epoch [0/20] Batch 400/938                   Loss D: 0.00040623178938403726, Loss G: 11.698454856872559\n",
      "Epoch [0/20] Batch 500/938                   Loss D: 0.05595643073320389, Loss G: 9.931100845336914\n",
      "Epoch [0/20] Batch 600/938                   Loss D: 0.013205916620790958, Loss G: 7.84675931930542\n",
      "Epoch [0/20] Batch 700/938                   Loss D: 0.0035287761129438877, Loss G: 6.478899002075195\n",
      "Epoch [0/20] Batch 800/938                   Loss D: 0.012762698344886303, Loss G: 8.530923843383789\n",
      "Epoch [0/20] Batch 900/938                   Loss D: 0.045039739459753036, Loss G: 11.292922973632812\n",
      "Epoch [1/20] Batch 0/938                   Loss D: 0.09847836196422577, Loss G: 7.747068881988525\n",
      "Epoch [1/20] Batch 100/938                   Loss D: 0.020741770043969154, Loss G: 6.808253288269043\n",
      "Epoch [1/20] Batch 200/938                   Loss D: 0.12099410593509674, Loss G: 11.826457023620605\n",
      "Epoch [1/20] Batch 300/938                   Loss D: 0.013666309416294098, Loss G: 9.95765209197998\n",
      "Epoch [1/20] Batch 400/938                   Loss D: 0.17101305723190308, Loss G: 12.645376205444336\n",
      "Epoch [1/20] Batch 500/938                   Loss D: 1.652016282081604, Loss G: 1.647460699081421\n",
      "Epoch [1/20] Batch 600/938                   Loss D: 0.5885168313980103, Loss G: 3.4044923782348633\n",
      "Epoch [1/20] Batch 700/938                   Loss D: 13.04995059967041, Loss G: 1.430062174797058\n",
      "Epoch [1/20] Batch 800/938                   Loss D: 0.5811665058135986, Loss G: 6.517763137817383\n",
      "Epoch [1/20] Batch 900/938                   Loss D: 0.4092358946800232, Loss G: 5.096307754516602\n",
      "Epoch [2/20] Batch 0/938                   Loss D: 2.3517301082611084, Loss G: 7.362267017364502\n",
      "Epoch [2/20] Batch 100/938                   Loss D: 2.0579946041107178, Loss G: 1.944870948791504\n",
      "Epoch [2/20] Batch 200/938                   Loss D: 0.8492119312286377, Loss G: 3.1652913093566895\n",
      "Epoch [2/20] Batch 300/938                   Loss D: 0.4776926636695862, Loss G: 4.865496635437012\n",
      "Epoch [2/20] Batch 400/938                   Loss D: 0.31292620301246643, Loss G: 2.3245809078216553\n",
      "Epoch [2/20] Batch 500/938                   Loss D: 0.8898311853408813, Loss G: 1.1886438131332397\n",
      "Epoch [2/20] Batch 600/938                   Loss D: 0.2474278062582016, Loss G: 2.7491962909698486\n",
      "Epoch [2/20] Batch 700/938                   Loss D: 0.08679187297821045, Loss G: 4.577672004699707\n",
      "Epoch [2/20] Batch 800/938                   Loss D: 1.03940749168396, Loss G: 2.135098934173584\n",
      "Epoch [2/20] Batch 900/938                   Loss D: 2.417849063873291, Loss G: 0.8696609139442444\n",
      "Epoch [3/20] Batch 0/938                   Loss D: 0.04945492744445801, Loss G: 3.6314897537231445\n",
      "Epoch [3/20] Batch 100/938                   Loss D: 1.2155128717422485, Loss G: 1.358457088470459\n",
      "Epoch [3/20] Batch 200/938                   Loss D: 1.855730652809143, Loss G: 2.320211410522461\n",
      "Epoch [3/20] Batch 300/938                   Loss D: 0.3747248649597168, Loss G: 2.808666706085205\n",
      "Epoch [3/20] Batch 400/938                   Loss D: 0.6131450533866882, Loss G: 2.5674049854278564\n",
      "Epoch [3/20] Batch 500/938                   Loss D: 0.38977551460266113, Loss G: 2.1562108993530273\n",
      "Epoch [3/20] Batch 600/938                   Loss D: 0.6065370440483093, Loss G: 2.4692063331604004\n",
      "Epoch [3/20] Batch 700/938                   Loss D: 0.2398524284362793, Loss G: 2.769784688949585\n",
      "Epoch [3/20] Batch 800/938                   Loss D: 0.23896434903144836, Loss G: 5.413686752319336\n",
      "Epoch [3/20] Batch 900/938                   Loss D: 0.1438513696193695, Loss G: 4.33540153503418\n",
      "Epoch [4/20] Batch 0/938                   Loss D: 0.5797220468521118, Loss G: 2.3301408290863037\n",
      "Epoch [4/20] Batch 100/938                   Loss D: 0.1901879459619522, Loss G: 5.496766090393066\n",
      "Epoch [4/20] Batch 200/938                   Loss D: 0.9258511066436768, Loss G: 2.0702192783355713\n",
      "Epoch [4/20] Batch 300/938                   Loss D: 0.1976293921470642, Loss G: 3.07169771194458\n",
      "Epoch [4/20] Batch 400/938                   Loss D: 0.5098060369491577, Loss G: 4.327098846435547\n",
      "Epoch [4/20] Batch 500/938                   Loss D: 0.5360832214355469, Loss G: 2.6743361949920654\n",
      "Epoch [4/20] Batch 600/938                   Loss D: 0.5750365257263184, Loss G: 2.753734827041626\n",
      "Epoch [4/20] Batch 700/938                   Loss D: 0.12204252183437347, Loss G: 4.972846031188965\n",
      "Epoch [4/20] Batch 800/938                   Loss D: 0.2580743432044983, Loss G: 5.582783222198486\n",
      "Epoch [4/20] Batch 900/938                   Loss D: 0.1524350345134735, Loss G: 4.085297107696533\n",
      "Epoch [5/20] Batch 0/938                   Loss D: 0.3946825861930847, Loss G: 5.181519508361816\n",
      "Epoch [5/20] Batch 100/938                   Loss D: 0.6405838131904602, Loss G: 4.208056926727295\n",
      "Epoch [5/20] Batch 200/938                   Loss D: 0.26098495721817017, Loss G: 4.942731857299805\n",
      "Epoch [5/20] Batch 300/938                   Loss D: 0.7492119073867798, Loss G: 5.29080867767334\n",
      "Epoch [5/20] Batch 400/938                   Loss D: 0.3487854599952698, Loss G: 3.301558494567871\n",
      "Epoch [5/20] Batch 500/938                   Loss D: 0.3087626099586487, Loss G: 3.5117454528808594\n",
      "Epoch [5/20] Batch 600/938                   Loss D: 0.23473769426345825, Loss G: 2.458284378051758\n",
      "Epoch [5/20] Batch 700/938                   Loss D: 0.7935596108436584, Loss G: 3.641810894012451\n",
      "Epoch [5/20] Batch 800/938                   Loss D: 0.32140201330184937, Loss G: 4.031675338745117\n",
      "Epoch [5/20] Batch 900/938                   Loss D: 0.45409703254699707, Loss G: 3.719788074493408\n",
      "Epoch [6/20] Batch 0/938                   Loss D: 0.3958752155303955, Loss G: 3.657562255859375\n",
      "Epoch [6/20] Batch 100/938                   Loss D: 0.1645391583442688, Loss G: 3.950867176055908\n",
      "Epoch [6/20] Batch 200/938                   Loss D: 0.12536406517028809, Loss G: 3.358029365539551\n",
      "Epoch [6/20] Batch 300/938                   Loss D: 0.5388392806053162, Loss G: 3.3979287147521973\n",
      "Epoch [6/20] Batch 400/938                   Loss D: 0.17907550930976868, Loss G: 4.104062557220459\n",
      "Epoch [6/20] Batch 500/938                   Loss D: 0.14979760348796844, Loss G: 4.766101837158203\n",
      "Epoch [6/20] Batch 600/938                   Loss D: 0.4315750002861023, Loss G: 4.763686656951904\n",
      "Epoch [6/20] Batch 700/938                   Loss D: 0.3732181787490845, Loss G: 4.466497421264648\n",
      "Epoch [6/20] Batch 800/938                   Loss D: 0.5461956262588501, Loss G: 4.083226203918457\n",
      "Epoch [6/20] Batch 900/938                   Loss D: 0.36818793416023254, Loss G: 4.558745384216309\n",
      "Epoch [7/20] Batch 0/938                   Loss D: 0.2958466410636902, Loss G: 7.445637226104736\n",
      "Epoch [7/20] Batch 100/938                   Loss D: 0.2579902410507202, Loss G: 4.659423828125\n",
      "Epoch [7/20] Batch 200/938                   Loss D: 0.35943084955215454, Loss G: 2.7937512397766113\n",
      "Epoch [7/20] Batch 300/938                   Loss D: 0.23846232891082764, Loss G: 3.0213587284088135\n",
      "Epoch [7/20] Batch 400/938                   Loss D: 0.11017272621393204, Loss G: 5.791167736053467\n",
      "Epoch [7/20] Batch 500/938                   Loss D: 0.072337806224823, Loss G: 5.074949741363525\n",
      "Epoch [7/20] Batch 600/938                   Loss D: 0.3914792835712433, Loss G: 3.492013931274414\n",
      "Epoch [7/20] Batch 700/938                   Loss D: 0.19771431386470795, Loss G: 4.054637432098389\n",
      "Epoch [7/20] Batch 800/938                   Loss D: 0.9166662096977234, Loss G: 7.433725833892822\n",
      "Epoch [7/20] Batch 900/938                   Loss D: 0.26634204387664795, Loss G: 4.463870525360107\n",
      "Epoch [8/20] Batch 0/938                   Loss D: 0.2819453477859497, Loss G: 4.380735397338867\n",
      "Epoch [8/20] Batch 100/938                   Loss D: 0.6797008514404297, Loss G: 3.8640503883361816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] Batch 200/938                   Loss D: 0.2576775550842285, Loss G: 5.129783630371094\n",
      "Epoch [8/20] Batch 300/938                   Loss D: 0.23205086588859558, Loss G: 4.131558418273926\n",
      "Epoch [8/20] Batch 400/938                   Loss D: 0.23609159886837006, Loss G: 4.478598594665527\n",
      "Epoch [8/20] Batch 500/938                   Loss D: 0.19304409623146057, Loss G: 3.796693801879883\n",
      "Epoch [8/20] Batch 600/938                   Loss D: 0.4978059232234955, Loss G: 5.269026279449463\n",
      "Epoch [8/20] Batch 700/938                   Loss D: 0.06880423426628113, Loss G: 5.254241466522217\n",
      "Epoch [8/20] Batch 800/938                   Loss D: 0.0813046544790268, Loss G: 5.640722274780273\n",
      "Epoch [8/20] Batch 900/938                   Loss D: 0.2547832727432251, Loss G: 4.055717945098877\n",
      "Epoch [9/20] Batch 0/938                   Loss D: 0.1305491328239441, Loss G: 4.923584461212158\n",
      "Epoch [9/20] Batch 100/938                   Loss D: 0.0895596519112587, Loss G: 5.67410945892334\n",
      "Epoch [9/20] Batch 200/938                   Loss D: 0.17771589756011963, Loss G: 5.592526912689209\n",
      "Epoch [9/20] Batch 300/938                   Loss D: 0.3220997154712677, Loss G: 5.004186153411865\n",
      "Epoch [9/20] Batch 400/938                   Loss D: 0.28054100275039673, Loss G: 3.0850963592529297\n",
      "Epoch [9/20] Batch 500/938                   Loss D: 0.32792162895202637, Loss G: 4.277927875518799\n",
      "Epoch [9/20] Batch 600/938                   Loss D: 0.10079529136419296, Loss G: 5.417002201080322\n",
      "Epoch [9/20] Batch 700/938                   Loss D: 0.24574679136276245, Loss G: 6.2504167556762695\n",
      "Epoch [9/20] Batch 800/938                   Loss D: 0.28235962986946106, Loss G: 6.426553726196289\n",
      "Epoch [9/20] Batch 900/938                   Loss D: 0.12371785193681717, Loss G: 4.868503570556641\n",
      "Epoch [10/20] Batch 0/938                   Loss D: 0.15010124444961548, Loss G: 5.986433982849121\n",
      "Epoch [10/20] Batch 100/938                   Loss D: 0.1164388433098793, Loss G: 5.549641132354736\n",
      "Epoch [10/20] Batch 200/938                   Loss D: 0.050727300345897675, Loss G: 6.231377601623535\n",
      "Epoch [10/20] Batch 300/938                   Loss D: 0.3003672957420349, Loss G: 4.4860148429870605\n",
      "Epoch [10/20] Batch 400/938                   Loss D: 0.12863647937774658, Loss G: 5.847541809082031\n",
      "Epoch [10/20] Batch 500/938                   Loss D: 0.21995146572589874, Loss G: 3.4104554653167725\n",
      "Epoch [10/20] Batch 600/938                   Loss D: 0.5723295211791992, Loss G: 5.241849422454834\n",
      "Epoch [10/20] Batch 700/938                   Loss D: 0.3607698976993561, Loss G: 4.337273597717285\n",
      "Epoch [10/20] Batch 800/938                   Loss D: 0.37086421251296997, Loss G: 4.5809245109558105\n",
      "Epoch [10/20] Batch 900/938                   Loss D: 0.11185911297798157, Loss G: 6.394118785858154\n",
      "Epoch [11/20] Batch 0/938                   Loss D: 0.38580524921417236, Loss G: 3.5626158714294434\n",
      "Epoch [11/20] Batch 100/938                   Loss D: 0.10573140531778336, Loss G: 5.570513725280762\n",
      "Epoch [11/20] Batch 200/938                   Loss D: 0.18974627554416656, Loss G: 5.526700496673584\n",
      "Epoch [11/20] Batch 300/938                   Loss D: 0.21755307912826538, Loss G: 4.38600492477417\n",
      "Epoch [11/20] Batch 400/938                   Loss D: 0.2829556465148926, Loss G: 5.274421215057373\n",
      "Epoch [11/20] Batch 500/938                   Loss D: 0.19970691204071045, Loss G: 4.801064491271973\n",
      "Epoch [11/20] Batch 600/938                   Loss D: 0.6069501042366028, Loss G: 5.575197696685791\n",
      "Epoch [11/20] Batch 700/938                   Loss D: 0.36217787861824036, Loss G: 4.22899055480957\n",
      "Epoch [11/20] Batch 800/938                   Loss D: 0.08704562485218048, Loss G: 4.5902509689331055\n",
      "Epoch [11/20] Batch 900/938                   Loss D: 0.5543038249015808, Loss G: 6.278913974761963\n",
      "Epoch [12/20] Batch 0/938                   Loss D: 0.3327467441558838, Loss G: 7.142118453979492\n",
      "Epoch [12/20] Batch 100/938                   Loss D: 0.3653349280357361, Loss G: 5.148332118988037\n",
      "Epoch [12/20] Batch 200/938                   Loss D: 0.27504682540893555, Loss G: 4.272129058837891\n",
      "Epoch [12/20] Batch 300/938                   Loss D: 0.4144192337989807, Loss G: 3.327636957168579\n",
      "Epoch [12/20] Batch 400/938                   Loss D: 0.23227596282958984, Loss G: 4.4664626121521\n",
      "Epoch [12/20] Batch 500/938                   Loss D: 0.17167988419532776, Loss G: 4.329902172088623\n",
      "Epoch [12/20] Batch 600/938                   Loss D: 0.21744497120380402, Loss G: 5.966310977935791\n",
      "Epoch [12/20] Batch 700/938                   Loss D: 0.2941962778568268, Loss G: 4.1622090339660645\n",
      "Epoch [12/20] Batch 800/938                   Loss D: 0.23239371180534363, Loss G: 5.673396110534668\n",
      "Epoch [12/20] Batch 900/938                   Loss D: 0.2645508050918579, Loss G: 3.2052228450775146\n",
      "Epoch [13/20] Batch 0/938                   Loss D: 0.4489125609397888, Loss G: 3.639085292816162\n",
      "Epoch [13/20] Batch 100/938                   Loss D: 0.29465800523757935, Loss G: 5.027743339538574\n",
      "Epoch [13/20] Batch 200/938                   Loss D: 0.2548045217990875, Loss G: 6.211617469787598\n",
      "Epoch [13/20] Batch 300/938                   Loss D: 0.27284136414527893, Loss G: 5.457980155944824\n",
      "Epoch [13/20] Batch 400/938                   Loss D: 0.1617572009563446, Loss G: 4.1501617431640625\n",
      "Epoch [13/20] Batch 500/938                   Loss D: 0.20958061516284943, Loss G: 3.373903512954712\n",
      "Epoch [13/20] Batch 600/938                   Loss D: 0.37697988748550415, Loss G: 4.249183654785156\n",
      "Epoch [13/20] Batch 700/938                   Loss D: 0.14560005068778992, Loss G: 4.77680778503418\n",
      "Epoch [13/20] Batch 800/938                   Loss D: 0.2796249985694885, Loss G: 4.930773735046387\n",
      "Epoch [13/20] Batch 900/938                   Loss D: 0.2004973143339157, Loss G: 3.4359488487243652\n",
      "Epoch [14/20] Batch 0/938                   Loss D: 0.1724654883146286, Loss G: 2.9064435958862305\n",
      "Epoch [14/20] Batch 100/938                   Loss D: 0.11803597211837769, Loss G: 2.7782115936279297\n",
      "Epoch [14/20] Batch 200/938                   Loss D: 0.1601557731628418, Loss G: 6.127255916595459\n",
      "Epoch [14/20] Batch 300/938                   Loss D: 0.3427172899246216, Loss G: 4.192296028137207\n",
      "Epoch [14/20] Batch 400/938                   Loss D: 0.2747947573661804, Loss G: 4.307977676391602\n",
      "Epoch [14/20] Batch 500/938                   Loss D: 0.2411026954650879, Loss G: 3.8438773155212402\n",
      "Epoch [14/20] Batch 600/938                   Loss D: 0.30140021443367004, Loss G: 4.253995895385742\n",
      "Epoch [14/20] Batch 700/938                   Loss D: 0.23258666694164276, Loss G: 3.7049849033355713\n",
      "Epoch [14/20] Batch 800/938                   Loss D: 0.22116802632808685, Loss G: 5.653133869171143\n",
      "Epoch [14/20] Batch 900/938                   Loss D: 0.3052279055118561, Loss G: 5.036489486694336\n",
      "Epoch [15/20] Batch 0/938                   Loss D: 0.4084954857826233, Loss G: 3.9856278896331787\n",
      "Epoch [15/20] Batch 100/938                   Loss D: 0.3834816813468933, Loss G: 2.86795711517334\n",
      "Epoch [15/20] Batch 200/938                   Loss D: 0.1709040254354477, Loss G: 5.202418327331543\n",
      "Epoch [15/20] Batch 300/938                   Loss D: 0.3703422546386719, Loss G: 3.1563117504119873\n",
      "Epoch [15/20] Batch 400/938                   Loss D: 0.19512289762496948, Loss G: 4.420036315917969\n",
      "Epoch [15/20] Batch 500/938                   Loss D: 0.2274077832698822, Loss G: 3.577112913131714\n",
      "Epoch [15/20] Batch 600/938                   Loss D: 0.6114136576652527, Loss G: 2.6695241928100586\n",
      "Epoch [15/20] Batch 700/938                   Loss D: 0.1564502716064453, Loss G: 4.391660690307617\n",
      "Epoch [15/20] Batch 800/938                   Loss D: 0.3091595470905304, Loss G: 3.8052642345428467\n",
      "Epoch [15/20] Batch 900/938                   Loss D: 0.26533499360084534, Loss G: 2.768775701522827\n",
      "Epoch [16/20] Batch 0/938                   Loss D: 0.35792410373687744, Loss G: 3.1008989810943604\n",
      "Epoch [16/20] Batch 100/938                   Loss D: 0.1878737211227417, Loss G: 6.170569896697998\n",
      "Epoch [16/20] Batch 200/938                   Loss D: 0.38417479395866394, Loss G: 5.420914649963379\n",
      "Epoch [16/20] Batch 300/938                   Loss D: 0.3302702307701111, Loss G: 3.3109123706817627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20] Batch 400/938                   Loss D: 0.4964970350265503, Loss G: 3.30446720123291\n",
      "Epoch [16/20] Batch 500/938                   Loss D: 0.4248071014881134, Loss G: 3.4845221042633057\n",
      "Epoch [16/20] Batch 600/938                   Loss D: 0.16023211181163788, Loss G: 4.49136209487915\n",
      "Epoch [16/20] Batch 700/938                   Loss D: 0.44253212213516235, Loss G: 2.7773475646972656\n",
      "Epoch [16/20] Batch 800/938                   Loss D: 0.27827656269073486, Loss G: 4.026714324951172\n",
      "Epoch [16/20] Batch 900/938                   Loss D: 0.7150179147720337, Loss G: 5.87007474899292\n",
      "Epoch [17/20] Batch 0/938                   Loss D: 0.08823823928833008, Loss G: 3.6295151710510254\n",
      "Epoch [17/20] Batch 100/938                   Loss D: 0.42300981283187866, Loss G: 3.2442479133605957\n",
      "Epoch [17/20] Batch 200/938                   Loss D: 0.24984610080718994, Loss G: 3.173337459564209\n",
      "Epoch [17/20] Batch 300/938                   Loss D: 0.6430570483207703, Loss G: 2.4875802993774414\n",
      "Epoch [17/20] Batch 400/938                   Loss D: 0.37507566809654236, Loss G: 3.030864715576172\n",
      "Epoch [17/20] Batch 500/938                   Loss D: 0.37815606594085693, Loss G: 3.308851718902588\n",
      "Epoch [17/20] Batch 600/938                   Loss D: 0.3161160349845886, Loss G: 3.226285934448242\n",
      "Epoch [17/20] Batch 700/938                   Loss D: 0.3890784978866577, Loss G: 2.7500476837158203\n",
      "Epoch [17/20] Batch 800/938                   Loss D: 0.2371586561203003, Loss G: 4.743833541870117\n",
      "Epoch [17/20] Batch 900/938                   Loss D: 0.28393760323524475, Loss G: 3.0702011585235596\n",
      "Epoch [18/20] Batch 0/938                   Loss D: 0.2930658757686615, Loss G: 4.103507995605469\n",
      "Epoch [18/20] Batch 100/938                   Loss D: 0.4356556534767151, Loss G: 2.899162530899048\n",
      "Epoch [18/20] Batch 200/938                   Loss D: 0.2868763208389282, Loss G: 2.9500982761383057\n",
      "Epoch [18/20] Batch 300/938                   Loss D: 0.3723810017108917, Loss G: 3.946443557739258\n",
      "Epoch [18/20] Batch 400/938                   Loss D: 0.5491585731506348, Loss G: 2.506948947906494\n",
      "Epoch [18/20] Batch 500/938                   Loss D: 0.5126872062683105, Loss G: 2.5490546226501465\n",
      "Epoch [18/20] Batch 600/938                   Loss D: 0.46094533801078796, Loss G: 2.227795124053955\n",
      "Epoch [18/20] Batch 700/938                   Loss D: 0.4585767984390259, Loss G: 3.7115116119384766\n",
      "Epoch [18/20] Batch 800/938                   Loss D: 0.5676385164260864, Loss G: 2.7842557430267334\n",
      "Epoch [18/20] Batch 900/938                   Loss D: 0.5366144180297852, Loss G: 2.473630428314209\n",
      "Epoch [19/20] Batch 0/938                   Loss D: 0.3291730284690857, Loss G: 3.684053659439087\n",
      "Epoch [19/20] Batch 100/938                   Loss D: 0.41491296887397766, Loss G: 3.5661818981170654\n",
      "Epoch [19/20] Batch 200/938                   Loss D: 0.45426830649375916, Loss G: 4.269111633300781\n",
      "Epoch [19/20] Batch 300/938                   Loss D: 0.42589038610458374, Loss G: 2.8345510959625244\n",
      "Epoch [19/20] Batch 400/938                   Loss D: 0.44877323508262634, Loss G: 2.187662363052368\n",
      "Epoch [19/20] Batch 500/938                   Loss D: 0.5823842287063599, Loss G: 2.1836307048797607\n",
      "Epoch [19/20] Batch 600/938                   Loss D: 0.2692347764968872, Loss G: 3.802706480026245\n",
      "Epoch [19/20] Batch 700/938                   Loss D: 0.6902813911437988, Loss G: 2.359276056289673\n",
      "Epoch [19/20] Batch 800/938                   Loss D: 0.4468052387237549, Loss G: 2.9630699157714844\n",
      "Epoch [19/20] Batch 900/938                   Loss D: 0.40549659729003906, Loss G: 2.7336411476135254\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "z_dim = 100\n",
    "num_epochs = 20\n",
    "image_size = 28 * 28\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "mnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset=mnist, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z).view(-1, 1, 28, 28)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(image_size, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        return self.fc(img_flat)\n",
    "\n",
    "generator = Generator(z_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "def generate_noise(batch_size, z_dim):\n",
    "    return torch.randn(batch_size, z_dim).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real_images, _) in enumerate(dataloader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        real_output = discriminator(real_images)\n",
    "        real_loss = criterion(real_output, real_labels)\n",
    "        \n",
    "        noise = generate_noise(batch_size, z_dim)\n",
    "        fake_images = generator(noise)\n",
    "        fake_output = discriminator(fake_images)\n",
    "        fake_loss = criterion(fake_output, fake_labels)\n",
    "        \n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        noise = generate_noise(batch_size, z_dim)\n",
    "        fake_images = generator(noise)\n",
    "        fake_output = discriminator(fake_images)\n",
    "        \n",
    "        g_loss = criterion(fake_output, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(dataloader)} \\\n",
    "                  Loss D: {d_loss.item()}, Loss G: {g_loss.item()}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise = generate_noise(64, z_dim)\n",
    "        fake_images = generator(noise)\n",
    "        save_image(fake_images, f\"gan_images_epoch_{epoch}.png\", normalize=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = generate_noise(64, z_dim)\n",
    "    fake_images = generator(noise)\n",
    "    save_image(fake_images, \"final_gan_images.png\", normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3983cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "543962de",
   "metadata": {},
   "source": [
    "# 4. Real-world applications [use cases, how they impact your business/product]\n",
    "\n",
    "## use cases\n",
    "\n",
    "### 1. Pose guided person image generation\n",
    "\n",
    "<img src='g5.png' />\n",
    "<img src='g6.png' />\n",
    "<img src='g10.png' />\n",
    "\n",
    "### 2. StarGAN\n",
    "\n",
    "<img src='g7.png' />\n",
    "\n",
    "<img src='g8.png' />\n",
    "\n",
    "### 3. Super resolution\n",
    "\n",
    "<img src='g9.png' />\n",
    "<img src='g3.png' />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3375a701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "877a06ec",
   "metadata": {},
   "source": [
    "### impact on the business\n",
    "\n",
    "10 GANs use cases in 2024: https://research.aimultiple.com/gan-use-cases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d831ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c365753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4226e550",
   "metadata": {},
   "source": [
    "# 5. Interactions [Questions&Answers, polls, scenario discussion]\n",
    "\n",
    "### QnA or polls\n",
    "\n",
    "TGAN - Tabular GAN -> https://github.com/sdv-dev/TGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f112fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Are GANs used in tabular data?\n",
    "\n",
    "- TGAN - use case - mimic the distribution of real tabular data\n",
    "\n",
    "advantages\n",
    "- data generation when you have limited dataset\n",
    "- you have imbalanced data - you can generalize it using GANs\n",
    "- anomaly detection - generate normal samples and indentify deviations\n",
    "\n",
    "\n",
    "mode collapse \n",
    "- if the data contains less categories or classes it will be difficult to generate tabular data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041bc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "296a890c",
   "metadata": {},
   "source": [
    "### business scenario discussion\n",
    "\n",
    "#### Transforming image-based retail business with GANs\n",
    "\n",
    "Overview: \n",
    "\n",
    "Imagine you are part of the leadership team at a major online retail company that specializes in fashion. \n",
    "\n",
    "The company has been exploring AI-based solutions to enhance customer experience, particularly around virtual try-ons and personalized recommendations. \n",
    "\n",
    "You're already leveraging deep learning models for product recommendations and some basic image processing tasks. \n",
    "\n",
    "<img src='g12.gif' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504af798",
   "metadata": {},
   "outputs": [],
   "source": [
    "do you feel the need of implementing GANs in this particular use case?\n",
    "\n",
    "engineers question - is there any traditional way of doing the same?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f18aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if you want to make any AI implementation successfull\n",
    "\n",
    "- check if the solution is irreversible\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "what concerns might rise from using GANs in fashion?\n",
    "\n",
    "how can the data used to train GANs may introduce bias and \n",
    "    how it will affect the customer satisfaction or the brand perception\n",
    "- monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "how you are going to justify the computational cost investment and ROI?\n",
    "\n",
    "compair traditional and new approaches to comeup with right decision\n",
    "\n",
    "engineers q: what infrastrucutre, skills, and tools are needed to make is a success\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b300b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da144c7f",
   "metadata": {},
   "source": [
    "# 6. Hands-On [case study, practical implementation]\n",
    "\n",
    "\n",
    "### case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963969e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba6c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4190b920",
   "metadata": {},
   "source": [
    "### implementation\n",
    "\n",
    "List of applications and demos: https://github.com/nashory/gans-awesome-applications\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0d004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe11f89d",
   "metadata": {},
   "source": [
    "### In production - AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bd9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "- Amazon SageMaker\n",
    "- Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510063b3",
   "metadata": {},
   "source": [
    "# Conclusion [summary, resources, what to do next]\n",
    "\n",
    "\n",
    "### summary pointers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b7537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b20488a4",
   "metadata": {},
   "source": [
    "### resources\n",
    "\n",
    "Research papers\n",
    "- https://arxiv.org/abs/1406.2661\n",
    "\n",
    "Blogs\n",
    "- https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- https://www.kaggle.com/code/songseungwon/pytorch-gan-basic-tutorial-for-beginner\n",
    "\n",
    "Video\n",
    "- https://www.youtube.com/watch?v=xBX2VlDgd4I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647eac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc9cca6",
   "metadata": {},
   "source": [
    "### what next\n",
    "\n",
    "You can work on these projects to add to your portfolio\n",
    "\n",
    "- Image restoration: https://github.com/TencentARC/GFPGAN\n",
    "- Pose with Style: https://github.com/BadourAlBahar/pose-with-style\n",
    "- Generating Anime character(Colab Notebook): https://colab.research.google.com/drive/15EGSIv_jZxDvYWODNwEG-I4pV9i3RwlN?usp=sharing\n",
    "- Text to Image generation by NVIDIA: https://blogs.nvidia.com/blog/gaugan2-ai-art-demo/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d49239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
